{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0feb4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel('Final_output.xlsx', sheet_name='Sheet1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5958a474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>Subjectivity Score</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex Words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Average Number of Words Per Sentence</th>\n",
       "      <th>Complex Word Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllable Count Per Word</th>\n",
       "      <th>Personal Pronouns</th>\n",
       "      <th>Average Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>15.541667</td>\n",
       "      <td>0.404624</td>\n",
       "      <td>6.378516</td>\n",
       "      <td>7.208333</td>\n",
       "      <td>70</td>\n",
       "      <td>173</td>\n",
       "      <td>2.121387</td>\n",
       "      <td>1</td>\n",
       "      <td>5.994220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.110831</td>\n",
       "      <td>20.909091</td>\n",
       "      <td>0.569270</td>\n",
       "      <td>8.591344</td>\n",
       "      <td>10.311688</td>\n",
       "      <td>452</td>\n",
       "      <td>794</td>\n",
       "      <td>2.537783</td>\n",
       "      <td>0</td>\n",
       "      <td>7.117128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.098101</td>\n",
       "      <td>21.535714</td>\n",
       "      <td>0.636076</td>\n",
       "      <td>8.868716</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>402</td>\n",
       "      <td>632</td>\n",
       "      <td>2.917722</td>\n",
       "      <td>0</td>\n",
       "      <td>8.088608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>38</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.327434</td>\n",
       "      <td>0.180223</td>\n",
       "      <td>23.568627</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>9.669875</td>\n",
       "      <td>12.294118</td>\n",
       "      <td>380</td>\n",
       "      <td>627</td>\n",
       "      <td>2.763955</td>\n",
       "      <td>0</td>\n",
       "      <td>7.826156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.077128</td>\n",
       "      <td>19.789474</td>\n",
       "      <td>0.507979</td>\n",
       "      <td>8.118981</td>\n",
       "      <td>9.894737</td>\n",
       "      <td>191</td>\n",
       "      <td>376</td>\n",
       "      <td>2.425532</td>\n",
       "      <td>0</td>\n",
       "      <td>7.316489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1  blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2  blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3  blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4  blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "\n",
       "   Positive Score  Negative Score  Polarity Score  Subjectivity Score  \\\n",
       "0               6               1        0.714286            0.040462   \n",
       "1              57              31        0.295455            0.110831   \n",
       "2              38              24        0.225806            0.098101   \n",
       "3              38              75       -0.327434            0.180223   \n",
       "4              21               8        0.448276            0.077128   \n",
       "\n",
       "   Average Sentence Length  Percentage of Complex Words  Fog Index  \\\n",
       "0                15.541667                     0.404624   6.378516   \n",
       "1                20.909091                     0.569270   8.591344   \n",
       "2                21.535714                     0.636076   8.868716   \n",
       "3                23.568627                     0.606061   9.669875   \n",
       "4                19.789474                     0.507979   8.118981   \n",
       "\n",
       "   Average Number of Words Per Sentence  Complex Word Count  Word Count  \\\n",
       "0                              7.208333                  70         173   \n",
       "1                             10.311688                 452         794   \n",
       "2                             11.285714                 402         632   \n",
       "3                             12.294118                 380         627   \n",
       "4                              9.894737                 191         376   \n",
       "\n",
       "   Syllable Count Per Word  Personal Pronouns  Average Word Length  \n",
       "0                 2.121387                  1             5.994220  \n",
       "1                 2.537783                  0             7.117128  \n",
       "2                 2.917722                  0             8.088608  \n",
       "3                 2.763955                  0             7.826156  \n",
       "4                 2.425532                  0             7.316489  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7a4d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL_ID', 'URL', 'Positive Score', 'Negative Score', 'Polarity Score',\n",
       "       'Subjectivity Score', 'Average Sentence Length',\n",
       "       'Percentage of Complex Words', 'Fog Index',\n",
       "       'Average Number of Words Per Sentence', 'Complex Word Count',\n",
       "       'Word Count', 'Syllable Count Per Word', 'Personal Pronouns',\n",
       "       'Average Word Length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0732415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ayan0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ayan0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Remove single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to each element in the 'URL' column\n",
    "data['Processed Text'] = data['URL'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e115f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Processed Text, dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Processed Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4e487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
